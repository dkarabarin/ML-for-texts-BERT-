{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio tensorflow transformers -q\n",
    "!pip install torch==2.0.0 torchvision==0.15.0 torchaudio==2.0.0 --index-url https://download.pytorch.org/whl/cpu -q\n",
    "!pip install transformers==4.30.0 scikit-learn pandas numpy matplotlib seaborn tqdm -q\n",
    "!pip install torch transformers scikit-learn pandas numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cpu\n",
      "Версия PyTorch: 2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "print(f\"Версия PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: (159292, 2)\n",
      "Распределение классов:\n",
      "0    143106\n",
      "1     16186\n",
      "Name: toxic, dtype: int64\n",
      "                                                text  toxic\n",
      "0  Explanation\\nWhy the edits made under my usern...      0\n",
      "1  D'aww! He matches this background colour I'm s...      0\n",
      "2  Hey man, I'm really not trying to edit war. It...      0\n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4  You, sir, are my hero. Any chance you remember...      0\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('/datasets/toxic_comments.csv',index_col=0)\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Распределение классов:\\n{df['toxic'].value_counts()}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Имеется датасет с 143 тыс положительных и 16 отрицательных отзывов. Так как я собираюсь использовать bert то не проводил лематизацию и баланс класов ответов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cpu\n",
      "Загружаю unitary/toxic-bert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Успешно загружена модель: unitary/toxic-bert\n",
      "Модель перемещена на cpu\n",
      "Размер датасета: 159292\n",
      "Колонки: ['text', 'toxic']\n",
      "Очищено 1000 текстов\n",
      "Размерность эмбеддингов: (1000, 768)\n",
      "Распределение классов: {0: 894, 1: 106}\n",
      "Веса классов: {0: 0.5592841, 1: 4.716981}\n",
      "Train size: 800, Test size: 200\n",
      "✓ Готово! Эмбеддинги созданы успешно\n",
      "Размер эмбеддингов: (1000, 768)\n",
      "Обучающая выборка: (800, 768)\n",
      "Тестовая выборка: (200, 768)\n",
      "Метки обучающей выборки: (800,)\n",
      "Метки тестовой выборки: (200,)\n",
      "\n",
      "Распределение классов в обучающей выборке:\n",
      "{0: 715, 1: 85}\n",
      "Распределение классов в тестовой выборке:\n",
      "{0: 179, 1: 21}\n"
     ]
    }
   ],
   "source": [
    "# Проверяем доступность устройств\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Очистка текста\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Загрузка только Toxic BERT\n",
    "def load_toxic_bert():\n",
    "    model_name = 'unitary/toxic-bert'\n",
    "    try:\n",
    "        print(f\"Загружаю {model_name}...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "        print(f\"✓ Успешно загружена модель: {model_name}\")\n",
    "        return tokenizer, model, model_name\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Не удалось загрузить Toxic BERT: {e}\")\n",
    "\n",
    "# Загружаем модель\n",
    "tokenizer, model, model_name = load_toxic_bert()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Модель перемещена на {device}\")\n",
    "\n",
    "def get_toxic_bert_embeddings(texts, batch_size=16):  \n",
    "    \"\"\"Получение эмбеддингов из Toxic BERT\"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Токенизация\n",
    "        encoded = tokenizer.batch_encode_plus(\n",
    "            batch_texts,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        # Переносим на нужное устройство\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "        \n",
    "        # Извлечение [CLS] токена\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.extend(cls_embeddings)\n",
    "    \n",
    "    return np.array(all_embeddings)\n",
    "\n",
    "def calculate_class_weights(labels):\n",
    "    \"\"\"Вычисление весов классов\"\"\"\n",
    "    unique_classes = np.unique(labels)\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_classes,\n",
    "        y=labels\n",
    "    )\n",
    "    \n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    print(f\"Веса классов: {dict(zip(unique_classes, class_weights.numpy()))}\")\n",
    "    return class_weights\n",
    "\n",
    "# Основной код\n",
    "def main():\n",
    "    # Предполагаем, что df уже определен\n",
    "    print(\"Размер датасета:\", len(df))\n",
    "    print(\"Колонки:\", df.columns.tolist())\n",
    "    \n",
    "    if 'text' not in df.columns:\n",
    "        raise ValueError(\"Колонка 'text' не найдена в датафрейме\")\n",
    "    \n",
    "    # Уменьшаем размер выборки\n",
    "    sample_size = min(1000, len(df))\n",
    "    sampled_df = df.sample(sample_size, random_state=42)\n",
    "    \n",
    "    # Очистка текста\n",
    "    sampled_df['text_clean'] = sampled_df['text'].apply(clean_text)\n",
    "    print(f\"Очищено {len(sampled_df)} текстов\")\n",
    "    \n",
    "    # Получение эмбеддингов\n",
    "    texts = sampled_df['text_clean'].tolist()\n",
    "    embeddings = get_toxic_bert_embeddings(texts)\n",
    "    print(f\"Размерность эмбеддингов: {embeddings.shape}\")\n",
    "    \n",
    "    # Проверяем наличие меток toxic\n",
    "    results = {\n",
    "        'embeddings': embeddings,\n",
    "        'sampled_df': sampled_df\n",
    "    }\n",
    "    \n",
    "    if 'toxic' in sampled_df.columns:\n",
    "        labels = sampled_df['toxic'].values\n",
    "        \n",
    "        # Анализ дисбаланса\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"Распределение классов: {dict(zip(unique, counts))}\")\n",
    "        \n",
    "        # Вычисление весов классов\n",
    "        class_weights = calculate_class_weights(labels)\n",
    "        results['class_weights'] = class_weights\n",
    "        \n",
    "        # Разделение на train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            embeddings, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "        results.update({\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()\n",
    "    \n",
    "    # Теперь можно получить отдельные переменные из results\n",
    "    embeddings = results['embeddings']\n",
    "    sampled_df = results['sampled_df']\n",
    "    \n",
    "    print(\"✓ Готово! Эмбеддинги созданы успешно\")\n",
    "    print(f\"Размер эмбеддингов: {embeddings.shape}\")\n",
    "    \n",
    "    # Разделение на обучающую и тестовую выборки\n",
    "    if 'toxic' in sampled_df.columns:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            embeddings, \n",
    "            sampled_df['toxic'].values, \n",
    "            test_size=0.2, \n",
    "            random_state=42,\n",
    "            stratify=sampled_df['toxic'].values\n",
    "        )\n",
    "\n",
    "        print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "        print(f\"Тестовая выборка: {X_test.shape}\")\n",
    "        print(f\"Метки обучающей выборки: {y_train.shape}\")\n",
    "        print(f\"Метки тестовой выборки: {y_test.shape}\")\n",
    "        \n",
    "        # Анализ распределения классов\n",
    "        print(\"\\nРаспределение классов в обучающей выборке:\")\n",
    "        unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "        print(dict(zip(unique_train, counts_train)))\n",
    "        \n",
    "        print(\"Распределение классов в тестовой выборке:\")\n",
    "        unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "        print(dict(zip(unique_test, counts_test)))\n",
    "        \n",
    "        # Сохраняем разделенные данные в results\n",
    "        results.update({\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test\n",
    "        })\n",
    "    else:\n",
    "        print(\"Колонка 'toxic' не найдена для разделения данных\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: (800, 768)\n",
      "Тестовая выборка: (200, 768)\n"
     ]
    }
   ],
   "source": [
    "# Разделение на обучающую и тестовую выборки\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #embeddings, \n",
    "    #sampled_df['toxic'].values, \n",
    "    #test_size=0.2, \n",
    "   # random_state=42,\n",
    "   # stratify=sampled_df['toxic'].values\n",
    "#)\n",
    "\n",
    "print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "print(f\"Тестовая выборка: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор параметров для Logistic Regression...\n",
      "Подбор параметров для Random Forest...\n",
      "Подбор параметров для SVM...\n",
      "\n",
      "Лучшие параметры Logistic Regression: {'C': 0.01, 'class_weight': None, 'solver': 'liblinear'}\n",
      "Лучший F1-score (CV): 0.9700\n",
      "\n",
      "Лучшие параметры Random Forest: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Лучший F1-score (CV): 0.9584\n",
      "\n",
      "Лучшие параметры SVM: {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Лучший F1-score (CV): 0.9597\n",
      "\n",
      "============================================================\n",
      "СРАВНЕНИЕ F1-SCORE НА КРОСС-ВАЛИДАЦИИ\n",
      "============================================================\n",
      "Logistic Regression: F1-score = 0.9700\n",
      "Random Forest: F1-score = 0.9584\n",
      "SVM: F1-score = 0.9597\n",
      "\n",
      "Лучшая модель на валидации: Logistic Regression (F1-score: 0.9700)\n"
     ]
    }
   ],
   "source": [
    "# 1. Логистическая регрессияв\n",
    "print(\"Подбор параметров для Logistic Regression...\")\n",
    "log_reg_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "log_reg_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    log_reg_param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "best_log_reg = log_reg_grid.best_estimator_\n",
    "\n",
    "# 2. Random Forest \n",
    "print(\"Подбор параметров для Random Forest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=3,  \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "#3 SVM\n",
    "print(\"Подбор параметров для SVM...\")\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(random_state=42, probability=True),\n",
    "    svm_param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "svm_grid.fit(X_train, y_train)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "\n",
    "\n",
    "# Лучшие параметры для каждой модели\n",
    "print(f\"\\nЛучшие параметры Logistic Regression: {log_reg_grid.best_params_}\")\n",
    "print(f\"Лучший F1-score (CV): {log_reg_grid.best_score_:.4f}\")\n",
    "\n",
    "print(f\"\\nЛучшие параметры Random Forest: {rf_grid.best_params_}\")\n",
    "print(f\"Лучший F1-score (CV): {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "print(f\"\\nЛучшие параметры SVM: {svm_grid.best_params_}\")\n",
    "print(f\"Лучший F1-score (CV): {svm_grid.best_score_:.4f}\")\n",
    "\n",
    "# Сравнение F1-score на кросс-валидации\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СРАВНЕНИЕ F1-SCORE НА КРОСС-ВАЛИДАЦИИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cv_scores = {\n",
    "    'Logistic Regression': log_reg_grid.best_score_,\n",
    "    'Random Forest': rf_grid.best_score_,\n",
    "    'SVM': svm_grid.best_score_\n",
    "}\n",
    "\n",
    "for model_name, score in cv_scores.items():\n",
    "    print(f\"{model_name}: F1-score = {score:.4f}\")\n",
    "\n",
    "# Определение лучшей модели по кросс-валидации\n",
    "best_model_name = max(cv_scores, key=cv_scores.get)\n",
    "best_cv_score = cv_scores[best_model_name]\n",
    "print(f\"\\nЛучшая модель на валидации: {best_model_name} (F1-score: {best_cv_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель: Logistic Regression\n",
      "F1-score на тестовых данных : 0.8947\n"
     ]
    }
   ],
   "source": [
    "if best_model_name == 'Logistic Regression':\n",
    "    best_model = best_log_reg\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = best_rf\n",
    "else:\n",
    "    best_model = best_svm\n",
    "\n",
    "# Предсказания на тестовых данных\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_pred_proba_test = best_model.predict_proba(X_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "\n",
    "print(f\"Лучшая модель: {best_model_name}\")\n",
    "print(f\"F1-score на тестовых данных : {f1_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Настроили toxic-bert эмбединги на подготовленых и очищенных данных, для ускорения работы выбрали 1000 строк. Обучили три модели логистическую регрессию, случайный лес и опорные вектора. При помощи крос валидации произвели подбор гиперпаратетров и оценили f1 на тренировочных данных. Лучшей моделью показала себя модельл логистической регрессиив с f1 0.97 на валидации и 0.894 тестовых данных учитывая вес изза дисбаланса класов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты предсказаний (с использованием Toxic BERT):\n",
      "--------------------------------------------------------------------------------\n",
      "1. This is a great article, thanks for sharing!\n",
      "   → Предсказание: \u001b[92mНЕ ТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.0012\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "2. You are so stupid and worthless, I hate you!\n",
      "   → Предсказание: \u001b[91mТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.9876\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "3. I completely disagree with your opinion on this matter.\n",
      "   → Предсказание: \u001b[92mНЕ ТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.0012\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "4. Go die in a hole, nobody wants you here!\n",
      "   → Предсказание: \u001b[91mТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.9501\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "5. Interesting perspective, I never thought about it that way.\n",
      "   → Предсказание: \u001b[92mНЕ ТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.0014\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "6. Your mother should have aborted you, you piece of trash!\n",
      "   → Предсказание: \u001b[91mТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.9879\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "7. Could you please provide more details about this topic?\n",
      "   → Предсказание: \u001b[92mНЕ ТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.0012\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "8. I hope you get cancer and suffer for eternity!\n",
      "   → Предсказание: \u001b[91mТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.8659\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "9. The weather is really nice today, isn't it?\n",
      "   → Предсказание: \u001b[92mНЕ ТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.0014\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "10. You're such an idiot, your opinion doesn't matter at all!\n",
      "   → Предсказание: \u001b[91mТОКСИЧНЫЙ\u001b[0m\n",
      "   → Вероятность токсичности: 0.9767\n",
      "   → Уверенность: Высокая\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Используемая финальная модель: LogisticRegression\n",
      "Используемая BERT модель: SVM\n",
      "Параметры модели: {'C': 0.01, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Пакетное предсказание для тестовых примеров:\n",
      "1. This is a great article, thanks for sharing!... → НЕ ТОКСИЧНЫЙ (0.001)\n",
      "2. You are so stupid and worthless, I hate you!... → ТОКСИЧНЫЙ (0.988)\n",
      "3. I completely disagree with your opinion on this ma... → НЕ ТОКСИЧНЫЙ (0.001)\n",
      "4. Go die in a hole, nobody wants you here!... → ТОКСИЧНЫЙ (0.950)\n",
      "5. Interesting perspective, I never thought about it ... → НЕ ТОКСИЧНЫЙ (0.001)\n",
      "6. Your mother should have aborted you, you piece of ... → ТОКСИЧНЫЙ (0.988)\n",
      "7. Could you please provide more details about this t... → НЕ ТОКСИЧНЫЙ (0.001)\n",
      "8. I hope you get cancer and suffer for eternity!... → ТОКСИЧНЫЙ (0.866)\n",
      "9. The weather is really nice today, isn't it?... → НЕ ТОКСИЧНЫЙ (0.001)\n",
      "10. You're such an idiot, your opinion doesn't matter ... → ТОКСИЧНЫЙ (0.977)\n"
     ]
    }
   ],
   "source": [
    "# Обучение на всех данных с лучшей моделью\n",
    "final_model = best_model  \n",
    "\n",
    "# Переобучение на всех данных\n",
    "final_model.fit(embeddings, sampled_df['toxic'].values)\n",
    "\n",
    "# Функция для предсказания новых комментариев с использованием Toxic BERT\n",
    "def predict_toxicity(text, model, tokenizer, bert_model):\n",
    "    # Очистка текста\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Токенизация\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        cleaned_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Переносим на нужное устройство\n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**encoded)\n",
    "    \n",
    "    # Получение эмбеддинга\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    # Предсказание\n",
    "    prediction = model.predict(cls_embedding)\n",
    "    \n",
    "    # Для моделей, которые поддерживают predict_proba\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probability = model.predict_proba(cls_embedding)[0, 1]\n",
    "    else:\n",
    "        # Для моделей без predict_proba (например, SVM)\n",
    "        probability = model.decision_function(cls_embedding)[0]\n",
    "        # Преобразуем в вероятность от 0 до 1\n",
    "        probability = 1 / (1 + np.exp(-probability))\n",
    "    \n",
    "    return prediction[0], probability\n",
    "\n",
    "# Используем уже загруженный Toxic BERT (не нужно загружать заново)\n",
    "# bert_model уже загружен ранее как model\n",
    "\n",
    "# Примеры для тестирования\n",
    "test_examples = [\n",
    "    \"This is a great article, thanks for sharing!\",\n",
    "    \"You are so stupid and worthless, I hate you!\",\n",
    "    \"I completely disagree with your opinion on this matter.\",\n",
    "    \"Go die in a hole, nobody wants you here!\",\n",
    "    \"Interesting perspective, I never thought about it that way.\",\n",
    "    \"Your mother should have aborted you, you piece of trash!\",\n",
    "    \"Could you please provide more details about this topic?\",\n",
    "    \"I hope you get cancer and suffer for eternity!\",\n",
    "    \"The weather is really nice today, isn't it?\",\n",
    "    \"You're such an idiot, your opinion doesn't matter at all!\"\n",
    "]\n",
    "\n",
    "# Тестирование на примерах\n",
    "print(\"\\nРезультаты предсказаний (с использованием Toxic BERT):\")\n",
    "print(\"-\" * 80)\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    prediction, probability = predict_toxicity(example, final_model, tokenizer, model)\n",
    "    toxicity_label = \"ТОКСИЧНЫЙ\" if prediction == 1 else \"НЕ ТОКСИЧНЫЙ\"\n",
    "    color = \"\\033[91m\" if prediction == 1 else \"\\033[92m\"  # Красный для токсичного, зеленый для нетоксичного\n",
    "    reset_color = \"\\033[0m\"\n",
    "    \n",
    "    print(f\"{i}. {example}\")\n",
    "    print(f\"   → Предсказание: {color}{toxicity_label}{reset_color}\")\n",
    "    print(f\"   → Вероятность токсичности: {probability:.4f}\")\n",
    "    \n",
    "    # Определение уровня уверенности\n",
    "    if probability > 0.8 or probability < 0.2:\n",
    "        confidence = \"Высокая\"\n",
    "    elif probability > 0.6 or probability < 0.4:\n",
    "        confidence = \"Средняя\"\n",
    "    else:\n",
    "        confidence = \"Низкая\"\n",
    "    \n",
    "    print(f\"   → Уверенность: {confidence}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Дополнительная информация о финальной модели\n",
    "print(f\"\\nИспользуемая финальная модель: {type(final_model).__name__}\")\n",
    "print(f\"Используемая BERT модель: {model_name}\")\n",
    "print(f\"Параметры модели: {final_model.get_params() if hasattr(final_model, 'get_params') else 'N/A'}\")\n",
    "\n",
    "# Функция для пакетного предсказания\n",
    "def predict_toxicity_batch(texts, model, tokenizer, bert_model, batch_size=8):\n",
    "    \"\"\"Предсказание токсичности для списка текстов\"\"\"\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_embeddings = []\n",
    "        \n",
    "        for text in batch_texts:\n",
    "            cleaned_text = clean_text(text)\n",
    "            \n",
    "            # Токенизация\n",
    "            encoded = tokenizer.encode_plus(\n",
    "                cleaned_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=128,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = bert_model(**encoded)\n",
    "            \n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            batch_embeddings.append(cls_embedding)\n",
    "        \n",
    "        batch_embeddings = np.vstack(batch_embeddings)\n",
    "        \n",
    "        # Предсказания для батча\n",
    "        batch_predictions = model.predict(batch_embeddings)\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            batch_probs = model.predict_proba(batch_embeddings)[:, 1]\n",
    "        else:\n",
    "            batch_scores = model.decision_function(batch_embeddings)\n",
    "            batch_probs = 1 / (1 + np.exp(-batch_scores))\n",
    "        \n",
    "        predictions.extend(batch_predictions)\n",
    "        probabilities.extend(batch_probs)\n",
    "    \n",
    "    return np.array(predictions), np.array(probabilities)\n",
    "\n",
    "# Пример пакетного предсказания\n",
    "print(\"\\nПакетное предсказание для тестовых примеров:\")\n",
    "batch_predictions, batch_probabilities = predict_toxicity_batch(test_examples, final_model, tokenizer, model)\n",
    "\n",
    "for i, (example, pred, prob) in enumerate(zip(test_examples, batch_predictions, batch_probabilities), 1):\n",
    "    toxicity_label = \"ТОКСИЧНЫЙ\" if pred == 1 else \"НЕ ТОКСИЧНЫЙ\"\n",
    "    print(f\"{i}. {example[:50]}... → {toxicity_label} ({prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Для проверки работы модели посмотри мкак она класфиицирует новые 10 коментариев, модель уверено справилась с оценкой коментариев по токсичности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий вывод: 1)Имеется датасет с 143 тыс положительных и 16 отрицательных отзывов. Так как я собираюсь использовать bert то не проводил лематизацию и баланс класов ответов.\n",
    "2) Настроили toxic-bert эмбединги на подготовленых и очищенных данных, для ускорения работы выбрали 1000 строк. Обучили три модели логистическую регрессию, случайный лес и опорные вектора. При помощи крос валидации произвели подбор гиперпаратетров и оценили f1 на тренировочных данных. Лучшей моделью показала себя модельл логистической регрессиив с f1 0.97 на валидации и 0.894 тестовых данных учитывая вес изза дисбаланса класов\n",
    "3) Для проверки работы модели посмотри мкак она класфиицирует новые 10 коментариев, модель уверено справилась с оценкой коментариев по токсичности."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4207,
    "start_time": "2025-09-09T13:11:59.998Z"
   },
   {
    "duration": 923,
    "start_time": "2025-09-09T13:12:04.207Z"
   },
   {
    "duration": 1047,
    "start_time": "2025-09-09T13:12:54.447Z"
   },
   {
    "duration": 5224,
    "start_time": "2025-09-09T13:14:28.639Z"
   },
   {
    "duration": 961,
    "start_time": "2025-09-09T13:14:33.865Z"
   },
   {
    "duration": 1108,
    "start_time": "2025-09-09T13:14:34.828Z"
   },
   {
    "duration": 951490,
    "start_time": "2025-09-09T13:14:35.939Z"
   },
   {
    "duration": 2584,
    "start_time": "2025-09-09T13:30:27.431Z"
   },
   {
    "duration": 84486,
    "start_time": "2025-09-09T13:30:30.025Z"
   },
   {
    "duration": 7094,
    "start_time": "2025-09-09T13:31:54.515Z"
   },
   {
    "duration": 567,
    "start_time": "2025-09-09T13:32:01.612Z"
   },
   {
    "duration": 85,
    "start_time": "2025-09-09T13:32:02.182Z"
   },
   {
    "duration": 52,
    "start_time": "2025-09-10T01:07:43.535Z"
   },
   {
    "duration": 4776,
    "start_time": "2025-09-10T01:07:47.036Z"
   },
   {
    "duration": 946,
    "start_time": "2025-09-10T01:07:51.815Z"
   },
   {
    "duration": 39,
    "start_time": "2025-09-10T01:07:52.763Z"
   },
   {
    "duration": 4203,
    "start_time": "2025-09-10T01:12:59.444Z"
   },
   {
    "duration": 2215,
    "start_time": "2025-09-10T01:16:12.439Z"
   },
   {
    "duration": 944,
    "start_time": "2025-09-10T01:17:03.909Z"
   },
   {
    "duration": 4484,
    "start_time": "2025-09-10T01:20:34.805Z"
   },
   {
    "duration": 938,
    "start_time": "2025-09-10T01:20:39.291Z"
   },
   {
    "duration": 52,
    "start_time": "2025-09-10T01:20:40.231Z"
   },
   {
    "duration": 27119,
    "start_time": "2025-09-10T01:21:04.315Z"
   },
   {
    "duration": 4387,
    "start_time": "2025-09-10T01:22:35.865Z"
   },
   {
    "duration": 3529,
    "start_time": "2025-09-10T01:23:19.337Z"
   },
   {
    "duration": 4510,
    "start_time": "2025-09-10T01:25:14.980Z"
   },
   {
    "duration": 378193,
    "start_time": "2025-09-10T01:25:41.085Z"
   },
   {
    "duration": 27,
    "start_time": "2025-09-10T01:32:05.378Z"
   },
   {
    "duration": 22,
    "start_time": "2025-09-10T01:32:25.028Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-10T01:33:14.047Z"
   },
   {
    "duration": 745,
    "start_time": "2025-09-10T01:33:18.607Z"
   },
   {
    "duration": 24,
    "start_time": "2025-09-10T01:33:45.511Z"
   },
   {
    "duration": 5,
    "start_time": "2025-09-10T01:34:05.678Z"
   },
   {
    "duration": 90833,
    "start_time": "2025-09-10T01:34:09.832Z"
   },
   {
    "duration": 3478,
    "start_time": "2025-09-10T01:43:31.160Z"
   },
   {
    "duration": 3561,
    "start_time": "2025-09-10T01:45:27.371Z"
   },
   {
    "duration": 2979,
    "start_time": "2025-09-10T01:46:10.385Z"
   },
   {
    "duration": 5453,
    "start_time": "2025-09-10T01:46:44.911Z"
   },
   {
    "duration": 4610,
    "start_time": "2025-09-10T01:47:13.867Z"
   },
   {
    "duration": 959,
    "start_time": "2025-09-10T01:47:18.479Z"
   },
   {
    "duration": 52,
    "start_time": "2025-09-10T01:47:19.440Z"
   },
   {
    "duration": 6157,
    "start_time": "2025-09-10T01:47:19.494Z"
   },
   {
    "duration": 343205,
    "start_time": "2025-09-10T01:47:25.652Z"
   },
   {
    "duration": 600,
    "start_time": "2025-09-10T01:53:08.860Z"
   },
   {
    "duration": 47700,
    "start_time": "2025-09-10T01:53:09.552Z"
   },
   {
    "duration": 3183,
    "start_time": "2025-09-10T01:53:57.260Z"
   },
   {
    "duration": 2763,
    "start_time": "2025-09-10T02:06:09.310Z"
   },
   {
    "duration": 2862,
    "start_time": "2025-09-10T02:06:29.375Z"
   },
   {
    "duration": 7597,
    "start_time": "2025-09-10T02:09:03.876Z"
   },
   {
    "duration": 169,
    "start_time": "2025-09-10T02:15:23.690Z"
   },
   {
    "duration": 7,
    "start_time": "2025-09-10T02:15:40.565Z"
   },
   {
    "duration": 4780,
    "start_time": "2025-09-10T02:23:06.305Z"
   },
   {
    "duration": 996,
    "start_time": "2025-09-10T02:23:11.087Z"
   },
   {
    "duration": 45,
    "start_time": "2025-09-10T02:23:12.084Z"
   },
   {
    "duration": 6479,
    "start_time": "2025-09-10T02:23:12.131Z"
   },
   {
    "duration": 378038,
    "start_time": "2025-09-10T02:23:18.613Z"
   },
   {
    "duration": 8,
    "start_time": "2025-09-10T02:29:36.653Z"
   },
   {
    "duration": 4678,
    "start_time": "2025-09-10T03:05:41.931Z"
   },
   {
    "duration": 979,
    "start_time": "2025-09-10T03:05:46.611Z"
   },
   {
    "duration": 44,
    "start_time": "2025-09-10T03:05:47.591Z"
   },
   {
    "duration": 6330,
    "start_time": "2025-09-10T03:05:47.650Z"
   },
   {
    "duration": 353499,
    "start_time": "2025-09-10T03:05:53.981Z"
   },
   {
    "duration": 7,
    "start_time": "2025-09-10T03:11:47.483Z"
   },
   {
    "duration": 1575471,
    "start_time": "2025-09-10T03:11:47.491Z"
   },
   {
    "duration": 9,
    "start_time": "2025-09-10T03:38:02.964Z"
   },
   {
    "duration": 461,
    "start_time": "2025-09-10T03:38:03.054Z"
   },
   {
    "duration": 31,
    "start_time": "2025-09-10T03:41:20.671Z"
   },
   {
    "duration": 4899,
    "start_time": "2025-09-10T03:46:53.707Z"
   },
   {
    "duration": 960,
    "start_time": "2025-09-10T03:46:58.608Z"
   },
   {
    "duration": 60,
    "start_time": "2025-09-10T03:46:59.569Z"
   },
   {
    "duration": 6511,
    "start_time": "2025-09-10T03:46:59.633Z"
   },
   {
    "duration": 460409,
    "start_time": "2025-09-10T03:47:06.152Z"
   },
   {
    "duration": 7,
    "start_time": "2025-09-10T03:54:46.563Z"
   },
   {
    "duration": 4649,
    "start_time": "2025-09-10T04:53:16.363Z"
   },
   {
    "duration": 959,
    "start_time": "2025-09-10T04:53:21.014Z"
   },
   {
    "duration": 42,
    "start_time": "2025-09-10T04:53:21.974Z"
   },
   {
    "duration": 6484,
    "start_time": "2025-09-10T04:53:22.019Z"
   },
   {
    "duration": 345883,
    "start_time": "2025-09-10T04:53:28.505Z"
   },
   {
    "duration": 61,
    "start_time": "2025-09-10T04:59:14.391Z"
   },
   {
    "duration": 1599622,
    "start_time": "2025-09-10T04:59:14.454Z"
   },
   {
    "duration": 80,
    "start_time": "2025-09-10T05:25:54.078Z"
   },
   {
    "duration": 9102,
    "start_time": "2025-09-10T05:25:54.161Z"
   },
   {
    "duration": 4593,
    "start_time": "2025-09-10T07:01:25.499Z"
   },
   {
    "duration": 942,
    "start_time": "2025-09-10T07:01:31.578Z"
   },
   {
    "duration": 93,
    "start_time": "2025-09-10T07:01:55.556Z"
   },
   {
    "duration": 6704,
    "start_time": "2025-09-10T07:03:44.562Z"
   },
   {
    "duration": 931,
    "start_time": "2025-09-10T07:03:51.268Z"
   },
   {
    "duration": 330,
    "start_time": "2025-09-10T07:03:58.515Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T07:04:04.620Z"
   },
   {
    "duration": 25838,
    "start_time": "2025-09-10T07:04:09.042Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T07:09:16.328Z"
   },
   {
    "duration": 2727,
    "start_time": "2025-09-10T07:10:00.256Z"
   },
   {
    "duration": 4991,
    "start_time": "2025-09-10T07:10:08.271Z"
   },
   {
    "duration": 925,
    "start_time": "2025-09-10T07:10:13.264Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T07:10:14.191Z"
   },
   {
    "duration": 99,
    "start_time": "2025-09-10T07:10:14.204Z"
   },
   {
    "duration": 2474,
    "start_time": "2025-09-10T07:10:14.305Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:10:16.781Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:10:16.782Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:10:16.783Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:10:16.784Z"
   },
   {
    "duration": 4286,
    "start_time": "2025-09-10T07:13:12.133Z"
   },
   {
    "duration": 908,
    "start_time": "2025-09-10T07:13:16.421Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T07:13:17.330Z"
   },
   {
    "duration": 2675,
    "start_time": "2025-09-10T07:13:17.335Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:13:20.011Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:13:20.013Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:13:20.014Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T07:13:20.016Z"
   },
   {
    "duration": 4163,
    "start_time": "2025-09-10T07:14:24.176Z"
   },
   {
    "duration": 907,
    "start_time": "2025-09-10T07:14:28.341Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T07:14:29.249Z"
   },
   {
    "duration": 336284,
    "start_time": "2025-09-10T07:14:29.254Z"
   },
   {
    "duration": 8,
    "start_time": "2025-09-10T07:20:05.540Z"
   },
   {
    "duration": 1484422,
    "start_time": "2025-09-10T07:20:05.604Z"
   },
   {
    "duration": 79,
    "start_time": "2025-09-10T07:44:50.028Z"
   },
   {
    "duration": 2338,
    "start_time": "2025-09-10T07:44:50.112Z"
   },
   {
    "duration": 57,
    "start_time": "2025-09-10T09:15:23.413Z"
   },
   {
    "duration": 4677,
    "start_time": "2025-09-10T09:15:28.682Z"
   },
   {
    "duration": 925,
    "start_time": "2025-09-10T09:15:33.361Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T09:15:34.288Z"
   },
   {
    "duration": 346508,
    "start_time": "2025-09-10T09:15:34.303Z"
   },
   {
    "duration": 337,
    "start_time": "2025-09-10T09:21:20.813Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T09:21:21.152Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T09:21:21.153Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T09:21:21.154Z"
   },
   {
    "duration": 4184,
    "start_time": "2025-09-10T10:07:18.121Z"
   },
   {
    "duration": 923,
    "start_time": "2025-09-10T10:07:22.307Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T10:07:23.232Z"
   },
   {
    "duration": 356582,
    "start_time": "2025-09-10T10:07:23.237Z"
   },
   {
    "duration": 344,
    "start_time": "2025-09-10T10:13:19.821Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T10:13:20.167Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T10:13:20.168Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T10:13:20.169Z"
   },
   {
    "duration": 7,
    "start_time": "2025-09-10T10:14:16.485Z"
   },
   {
    "duration": 1596175,
    "start_time": "2025-09-10T10:14:19.251Z"
   },
   {
    "duration": 95,
    "start_time": "2025-09-10T10:40:55.428Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T10:40:55.525Z"
   },
   {
    "duration": 9,
    "start_time": "2025-09-10T10:48:15.310Z"
   },
   {
    "duration": 19,
    "start_time": "2025-09-10T10:51:28.076Z"
   },
   {
    "duration": 5584,
    "start_time": "2025-09-10T10:51:52.276Z"
   },
   {
    "duration": 2718,
    "start_time": "2025-09-10T10:51:58.048Z"
   },
   {
    "duration": 79,
    "start_time": "2025-09-10T10:52:00.769Z"
   },
   {
    "duration": 197,
    "start_time": "2025-09-10T10:52:11.228Z"
   },
   {
    "duration": 107,
    "start_time": "2025-09-10T10:53:09.599Z"
   },
   {
    "duration": 52,
    "start_time": "2025-09-10T10:54:43.760Z"
   },
   {
    "duration": 2159,
    "start_time": "2025-09-10T10:56:35.728Z"
   },
   {
    "duration": 12552,
    "start_time": "2025-09-10T10:59:13.184Z"
   },
   {
    "duration": 53205,
    "start_time": "2025-09-10T11:00:34.324Z"
   },
   {
    "duration": 5,
    "start_time": "2025-09-10T11:01:47.677Z"
   },
   {
    "duration": 2058,
    "start_time": "2025-09-10T11:01:59.884Z"
   },
   {
    "duration": 7376,
    "start_time": "2025-09-10T11:03:33.145Z"
   },
   {
    "duration": 65,
    "start_time": "2025-09-10T11:07:44.669Z"
   },
   {
    "duration": 60,
    "start_time": "2025-09-10T11:08:14.588Z"
   },
   {
    "duration": 58,
    "start_time": "2025-09-10T11:08:34.975Z"
   },
   {
    "duration": 4426,
    "start_time": "2025-09-10T11:08:50.100Z"
   },
   {
    "duration": 2196,
    "start_time": "2025-09-10T11:09:00.369Z"
   },
   {
    "duration": 2591,
    "start_time": "2025-09-10T11:09:09.963Z"
   },
   {
    "duration": 4256,
    "start_time": "2025-09-10T11:09:12.556Z"
   },
   {
    "duration": 904,
    "start_time": "2025-09-10T11:09:16.813Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T11:09:17.719Z"
   },
   {
    "duration": 394029,
    "start_time": "2025-09-10T11:09:17.724Z"
   },
   {
    "duration": 54,
    "start_time": "2025-09-10T11:15:51.755Z"
   },
   {
    "duration": 2649809,
    "start_time": "2025-09-10T11:15:51.811Z"
   },
   {
    "duration": 40091,
    "start_time": "2025-09-10T12:00:01.623Z"
   },
   {
    "duration": 359,
    "start_time": "2025-09-10T12:00:41.716Z"
   },
   {
    "duration": 2628,
    "start_time": "2025-09-10T12:08:46.944Z"
   },
   {
    "duration": 4355,
    "start_time": "2025-09-10T12:08:49.575Z"
   },
   {
    "duration": 952,
    "start_time": "2025-09-10T12:08:53.932Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T12:08:54.887Z"
   },
   {
    "duration": 26,
    "start_time": "2025-09-10T12:08:54.891Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T12:08:54.919Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T12:08:54.920Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T12:08:54.921Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T12:08:54.923Z"
   },
   {
    "duration": 2718,
    "start_time": "2025-09-10T12:09:33.683Z"
   },
   {
    "duration": 4512,
    "start_time": "2025-09-10T12:09:36.405Z"
   },
   {
    "duration": 954,
    "start_time": "2025-09-10T12:09:40.918Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T12:09:41.875Z"
   },
   {
    "duration": 68,
    "start_time": "2025-09-10T12:15:54.329Z"
   },
   {
    "duration": 2679,
    "start_time": "2025-09-10T12:16:03.969Z"
   },
   {
    "duration": 4490,
    "start_time": "2025-09-10T12:16:06.651Z"
   },
   {
    "duration": 924,
    "start_time": "2025-09-10T12:16:11.142Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T12:16:12.068Z"
   },
   {
    "duration": 71,
    "start_time": "2025-09-10T12:17:53.253Z"
   },
   {
    "duration": 2728,
    "start_time": "2025-09-10T12:17:57.004Z"
   },
   {
    "duration": 4633,
    "start_time": "2025-09-10T12:17:59.734Z"
   },
   {
    "duration": 934,
    "start_time": "2025-09-10T12:18:04.368Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T12:18:05.304Z"
   },
   {
    "duration": 2612,
    "start_time": "2025-09-10T12:18:42.800Z"
   },
   {
    "duration": 4422,
    "start_time": "2025-09-10T12:18:45.415Z"
   },
   {
    "duration": 914,
    "start_time": "2025-09-10T12:18:49.839Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T12:18:50.756Z"
   },
   {
    "duration": 2660,
    "start_time": "2025-09-10T12:19:14.824Z"
   },
   {
    "duration": 4440,
    "start_time": "2025-09-10T12:19:17.486Z"
   },
   {
    "duration": 920,
    "start_time": "2025-09-10T12:19:21.927Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T12:19:22.850Z"
   },
   {
    "duration": 2668,
    "start_time": "2025-09-10T12:22:19.829Z"
   },
   {
    "duration": 4607,
    "start_time": "2025-09-10T12:22:22.500Z"
   },
   {
    "duration": 954,
    "start_time": "2025-09-10T12:22:27.108Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T12:22:28.065Z"
   },
   {
    "duration": 2573,
    "start_time": "2025-09-10T12:26:50.069Z"
   },
   {
    "duration": 4389,
    "start_time": "2025-09-10T12:26:52.644Z"
   },
   {
    "duration": 952,
    "start_time": "2025-09-10T12:26:57.034Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T12:26:57.988Z"
   },
   {
    "duration": 2658,
    "start_time": "2025-09-10T12:31:06.794Z"
   },
   {
    "duration": 4877,
    "start_time": "2025-09-10T12:31:09.455Z"
   },
   {
    "duration": 947,
    "start_time": "2025-09-10T12:31:14.333Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T12:31:15.282Z"
   },
   {
    "duration": 2652,
    "start_time": "2025-09-10T13:08:45.329Z"
   },
   {
    "duration": 4706,
    "start_time": "2025-09-10T13:08:47.984Z"
   },
   {
    "duration": 925,
    "start_time": "2025-09-10T13:08:52.692Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T13:08:53.619Z"
   },
   {
    "duration": 2700,
    "start_time": "2025-09-10T13:12:19.436Z"
   },
   {
    "duration": 4546,
    "start_time": "2025-09-10T13:12:22.138Z"
   },
   {
    "duration": 1067,
    "start_time": "2025-09-10T13:12:26.686Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T13:12:27.755Z"
   },
   {
    "duration": 1886,
    "start_time": "2025-09-10T13:12:27.759Z"
   },
   {
    "duration": 2667,
    "start_time": "2025-09-10T13:14:41.799Z"
   },
   {
    "duration": 4628,
    "start_time": "2025-09-10T13:14:44.469Z"
   },
   {
    "duration": 1015,
    "start_time": "2025-09-10T13:14:49.099Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T13:14:50.116Z"
   },
   {
    "duration": 1885,
    "start_time": "2025-09-10T13:14:50.120Z"
   },
   {
    "duration": 2708,
    "start_time": "2025-09-10T13:15:04.612Z"
   },
   {
    "duration": 2752,
    "start_time": "2025-09-10T13:15:32.796Z"
   },
   {
    "duration": 4481,
    "start_time": "2025-09-10T13:15:35.550Z"
   },
   {
    "duration": 983,
    "start_time": "2025-09-10T13:15:40.033Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T13:15:41.018Z"
   },
   {
    "duration": 1869,
    "start_time": "2025-09-10T13:15:41.022Z"
   },
   {
    "duration": 2751,
    "start_time": "2025-09-10T13:15:59.892Z"
   },
   {
    "duration": 4502,
    "start_time": "2025-09-10T13:16:02.647Z"
   },
   {
    "duration": 1011,
    "start_time": "2025-09-10T13:16:07.151Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-10T13:16:08.164Z"
   },
   {
    "duration": 2030,
    "start_time": "2025-09-10T13:16:08.170Z"
   },
   {
    "duration": 3002,
    "start_time": "2025-09-10T13:20:19.645Z"
   },
   {
    "duration": 5042,
    "start_time": "2025-09-10T13:20:22.650Z"
   },
   {
    "duration": 1058,
    "start_time": "2025-09-10T13:20:27.694Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T13:20:28.754Z"
   },
   {
    "duration": 1887,
    "start_time": "2025-09-10T13:20:28.759Z"
   },
   {
    "duration": 2862,
    "start_time": "2025-09-10T13:23:20.757Z"
   },
   {
    "duration": 4647,
    "start_time": "2025-09-10T13:23:23.623Z"
   },
   {
    "duration": 1025,
    "start_time": "2025-09-10T13:23:28.273Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T13:23:29.300Z"
   },
   {
    "duration": 1871,
    "start_time": "2025-09-10T13:23:29.306Z"
   },
   {
    "duration": 62460,
    "start_time": "2025-09-10T13:23:31.179Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T13:24:33.641Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T13:24:33.642Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T13:24:33.643Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T13:24:33.644Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T13:24:33.645Z"
   },
   {
    "duration": 1910,
    "start_time": "2025-09-10T13:28:31.733Z"
   },
   {
    "duration": 2609,
    "start_time": "2025-09-10T13:28:55.957Z"
   },
   {
    "duration": 4336,
    "start_time": "2025-09-10T13:28:58.569Z"
   },
   {
    "duration": 924,
    "start_time": "2025-09-10T13:29:02.906Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T13:29:03.832Z"
   },
   {
    "duration": 1917,
    "start_time": "2025-09-10T13:29:03.836Z"
   },
   {
    "duration": 58,
    "start_time": "2025-09-10T13:44:10.966Z"
   },
   {
    "duration": 4895,
    "start_time": "2025-09-10T13:44:14.018Z"
   },
   {
    "duration": 1001,
    "start_time": "2025-09-10T13:44:19.897Z"
   },
   {
    "duration": 2941,
    "start_time": "2025-09-10T13:45:24.657Z"
   },
   {
    "duration": 4958,
    "start_time": "2025-09-10T13:45:27.601Z"
   },
   {
    "duration": 1077,
    "start_time": "2025-09-10T13:45:32.560Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T13:45:33.639Z"
   },
   {
    "duration": 1990,
    "start_time": "2025-09-10T13:45:33.645Z"
   },
   {
    "duration": 2607,
    "start_time": "2025-09-10T14:05:39.510Z"
   },
   {
    "duration": 4830,
    "start_time": "2025-09-10T14:05:42.120Z"
   },
   {
    "duration": 1064,
    "start_time": "2025-09-10T14:05:46.952Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T14:05:48.018Z"
   },
   {
    "duration": 1984,
    "start_time": "2025-09-10T14:05:48.023Z"
   },
   {
    "duration": 2622,
    "start_time": "2025-09-10T14:09:31.665Z"
   },
   {
    "duration": 4768,
    "start_time": "2025-09-10T14:09:34.289Z"
   },
   {
    "duration": 984,
    "start_time": "2025-09-10T14:09:39.059Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T14:09:40.045Z"
   },
   {
    "duration": 1989,
    "start_time": "2025-09-10T14:09:40.049Z"
   },
   {
    "duration": 2671,
    "start_time": "2025-09-10T14:13:11.931Z"
   },
   {
    "duration": 4653,
    "start_time": "2025-09-10T14:13:14.604Z"
   },
   {
    "duration": 975,
    "start_time": "2025-09-10T14:13:19.259Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T14:13:20.236Z"
   },
   {
    "duration": 1939,
    "start_time": "2025-09-10T14:13:20.241Z"
   },
   {
    "duration": 42544,
    "start_time": "2025-09-10T14:13:22.183Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T14:14:04.728Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T14:14:04.730Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T14:14:04.731Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T14:14:04.733Z"
   },
   {
    "duration": 2666,
    "start_time": "2025-09-10T14:15:43.819Z"
   },
   {
    "duration": 4383,
    "start_time": "2025-09-10T14:15:46.487Z"
   },
   {
    "duration": 927,
    "start_time": "2025-09-10T14:15:50.871Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T14:15:51.803Z"
   },
   {
    "duration": 1887,
    "start_time": "2025-09-10T14:15:51.807Z"
   },
   {
    "duration": 2667,
    "start_time": "2025-09-10T14:17:15.651Z"
   },
   {
    "duration": 4602,
    "start_time": "2025-09-10T14:17:18.321Z"
   },
   {
    "duration": 965,
    "start_time": "2025-09-10T14:17:22.925Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T14:17:23.892Z"
   },
   {
    "duration": 2005,
    "start_time": "2025-09-10T14:17:23.896Z"
   },
   {
    "duration": 2675,
    "start_time": "2025-09-10T14:19:05.703Z"
   },
   {
    "duration": 4416,
    "start_time": "2025-09-10T14:19:08.381Z"
   },
   {
    "duration": 987,
    "start_time": "2025-09-10T14:19:12.798Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T14:19:13.788Z"
   },
   {
    "duration": 1984,
    "start_time": "2025-09-10T14:19:13.792Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T14:22:16.389Z"
   },
   {
    "duration": 2815,
    "start_time": "2025-09-10T14:23:15.920Z"
   },
   {
    "duration": 4578,
    "start_time": "2025-09-10T14:23:18.737Z"
   },
   {
    "duration": 923,
    "start_time": "2025-09-10T14:23:23.317Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T14:23:24.242Z"
   },
   {
    "duration": 1922,
    "start_time": "2025-09-10T14:23:24.246Z"
   },
   {
    "duration": 3532,
    "start_time": "2025-09-10T14:25:02.564Z"
   },
   {
    "duration": 4389,
    "start_time": "2025-09-10T14:25:06.099Z"
   },
   {
    "duration": 921,
    "start_time": "2025-09-10T14:25:10.490Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T14:25:11.413Z"
   },
   {
    "duration": 102123,
    "start_time": "2025-09-10T14:25:11.416Z"
   },
   {
    "duration": 69,
    "start_time": "2025-09-10T14:26:53.541Z"
   },
   {
    "duration": 3056,
    "start_time": "2025-09-10T14:27:09.357Z"
   },
   {
    "duration": 4456,
    "start_time": "2025-09-10T14:27:12.415Z"
   },
   {
    "duration": 932,
    "start_time": "2025-09-10T14:27:16.872Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T14:27:17.806Z"
   },
   {
    "duration": 40517,
    "start_time": "2025-09-10T14:27:17.810Z"
   },
   {
    "duration": 7,
    "start_time": "2025-09-10T14:27:58.329Z"
   },
   {
    "duration": 2612,
    "start_time": "2025-09-10T14:28:58.332Z"
   },
   {
    "duration": 4153,
    "start_time": "2025-09-10T14:29:00.946Z"
   },
   {
    "duration": 955,
    "start_time": "2025-09-10T14:29:05.101Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-10T14:29:06.059Z"
   },
   {
    "duration": 186676,
    "start_time": "2025-09-10T14:29:06.063Z"
   },
   {
    "duration": 7,
    "start_time": "2025-09-10T14:32:12.741Z"
   },
   {
    "duration": 415014,
    "start_time": "2025-09-10T14:32:12.805Z"
   },
   {
    "duration": 333,
    "start_time": "2025-09-10T14:39:07.821Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T14:39:08.156Z"
   },
   {
    "duration": 2576,
    "start_time": "2025-09-10T14:44:37.565Z"
   },
   {
    "duration": 4126,
    "start_time": "2025-09-10T14:44:40.144Z"
   },
   {
    "duration": 955,
    "start_time": "2025-09-10T14:44:44.271Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T14:44:45.228Z"
   },
   {
    "duration": 867914,
    "start_time": "2025-09-10T14:44:45.232Z"
   },
   {
    "duration": 11,
    "start_time": "2025-09-10T14:59:13.148Z"
   },
   {
    "duration": 2576,
    "start_time": "2025-09-10T15:02:02.330Z"
   },
   {
    "duration": 4746,
    "start_time": "2025-09-10T15:02:04.908Z"
   },
   {
    "duration": 951,
    "start_time": "2025-09-10T15:02:09.656Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T15:02:10.610Z"
   },
   {
    "duration": 2670,
    "start_time": "2025-09-10T15:02:59.874Z"
   },
   {
    "duration": 4348,
    "start_time": "2025-09-10T15:03:02.546Z"
   },
   {
    "duration": 941,
    "start_time": "2025-09-10T15:03:06.896Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-10T15:03:07.839Z"
   },
   {
    "duration": 177794,
    "start_time": "2025-09-10T15:03:07.843Z"
   },
   {
    "duration": 7,
    "start_time": "2025-09-10T15:06:05.639Z"
   },
   {
    "duration": 419399,
    "start_time": "2025-09-10T15:06:05.705Z"
   },
   {
    "duration": 332,
    "start_time": "2025-09-10T15:13:05.106Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-10T15:13:05.439Z"
   },
   {
    "duration": 23,
    "start_time": "2025-09-10T15:15:56.719Z"
   },
   {
    "duration": 25,
    "start_time": "2025-09-10T15:16:21.259Z"
   },
   {
    "duration": 22,
    "start_time": "2025-09-10T15:16:50.695Z"
   },
   {
    "duration": 22,
    "start_time": "2025-09-10T15:17:32.223Z"
   },
   {
    "duration": 24,
    "start_time": "2025-09-10T15:17:48.847Z"
   },
   {
    "duration": 52,
    "start_time": "2025-09-10T15:18:08.200Z"
   },
   {
    "duration": 26,
    "start_time": "2025-09-10T15:18:15.267Z"
   },
   {
    "duration": 25,
    "start_time": "2025-09-10T15:18:24.447Z"
   },
   {
    "duration": 7821,
    "start_time": "2025-09-10T15:20:49.289Z"
   },
   {
    "duration": 5792,
    "start_time": "2025-09-11T01:02:49.532Z"
   },
   {
    "duration": 4665,
    "start_time": "2025-09-11T01:02:55.327Z"
   },
   {
    "duration": 941,
    "start_time": "2025-09-11T01:02:59.993Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T01:03:00.936Z"
   },
   {
    "duration": 351,
    "start_time": "2025-09-11T01:03:00.940Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:03:01.293Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:03:01.294Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:03:01.295Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:03:01.297Z"
   },
   {
    "duration": 2674,
    "start_time": "2025-09-11T01:04:44.688Z"
   },
   {
    "duration": 4480,
    "start_time": "2025-09-11T01:04:47.365Z"
   },
   {
    "duration": 960,
    "start_time": "2025-09-11T01:04:51.846Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T01:04:52.808Z"
   },
   {
    "duration": 961,
    "start_time": "2025-09-11T01:04:52.812Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:04:53.775Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:04:53.776Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:04:53.777Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:04:53.778Z"
   },
   {
    "duration": 2607,
    "start_time": "2025-09-11T01:06:39.340Z"
   },
   {
    "duration": 4529,
    "start_time": "2025-09-11T01:06:41.949Z"
   },
   {
    "duration": 947,
    "start_time": "2025-09-11T01:06:46.480Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T01:06:47.429Z"
   },
   {
    "duration": 959,
    "start_time": "2025-09-11T01:06:47.434Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:06:48.394Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:06:48.396Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:06:48.397Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:06:48.398Z"
   },
   {
    "duration": 2835,
    "start_time": "2025-09-11T01:07:30.247Z"
   },
   {
    "duration": 6175,
    "start_time": "2025-09-11T01:07:33.085Z"
   },
   {
    "duration": 951,
    "start_time": "2025-09-11T01:07:39.261Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T01:07:40.214Z"
   },
   {
    "duration": 1111,
    "start_time": "2025-09-11T01:07:40.219Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:07:41.332Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:07:41.333Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:07:41.334Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:07:41.336Z"
   },
   {
    "duration": 20370,
    "start_time": "2025-09-11T01:09:03.968Z"
   },
   {
    "duration": 4480,
    "start_time": "2025-09-11T01:09:24.341Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:09:28.823Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:09:28.824Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:09:28.825Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:09:28.826Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:09:28.827Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:09:28.828Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:09:28.829Z"
   },
   {
    "duration": 5,
    "start_time": "2025-09-11T01:10:04.396Z"
   },
   {
    "duration": 924,
    "start_time": "2025-09-11T01:10:08.597Z"
   },
   {
    "duration": 3440,
    "start_time": "2025-09-11T01:10:15.128Z"
   },
   {
    "duration": 6165,
    "start_time": "2025-09-11T01:11:17.955Z"
   },
   {
    "duration": 4689,
    "start_time": "2025-09-11T01:11:24.123Z"
   },
   {
    "duration": 938,
    "start_time": "2025-09-11T01:11:28.813Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-11T01:11:29.754Z"
   },
   {
    "duration": 1987,
    "start_time": "2025-09-11T01:11:29.758Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:31.751Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:31.752Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:31.753Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:31.755Z"
   },
   {
    "duration": 9785,
    "start_time": "2025-09-11T01:11:41.981Z"
   },
   {
    "duration": 4247,
    "start_time": "2025-09-11T01:11:51.768Z"
   },
   {
    "duration": 937,
    "start_time": "2025-09-11T01:11:56.017Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T01:11:56.956Z"
   },
   {
    "duration": 1830,
    "start_time": "2025-09-11T01:11:56.961Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:58.793Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:58.794Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:58.795Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:11:58.797Z"
   },
   {
    "duration": 9547,
    "start_time": "2025-09-11T01:13:02.731Z"
   },
   {
    "duration": 6,
    "start_time": "2025-09-11T01:13:13.597Z"
   },
   {
    "duration": 947,
    "start_time": "2025-09-11T01:13:23.310Z"
   },
   {
    "duration": 1662,
    "start_time": "2025-09-11T01:13:28.135Z"
   },
   {
    "duration": 112,
    "start_time": "2025-09-11T01:14:32.981Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T01:14:38.916Z"
   },
   {
    "duration": 30630,
    "start_time": "2025-09-11T01:17:54.112Z"
   },
   {
    "duration": 6498,
    "start_time": "2025-09-11T01:18:24.745Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T01:18:31.245Z"
   },
   {
    "duration": 1008,
    "start_time": "2025-09-11T01:18:31.251Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T01:18:32.260Z"
   },
   {
    "duration": 2049,
    "start_time": "2025-09-11T01:18:32.265Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:18:34.315Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:18:34.317Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:18:34.318Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:18:34.320Z"
   },
   {
    "duration": 6264,
    "start_time": "2025-09-11T01:19:44.796Z"
   },
   {
    "duration": 8782,
    "start_time": "2025-09-11T01:19:51.063Z"
   },
   {
    "duration": 951,
    "start_time": "2025-09-11T01:19:59.847Z"
   },
   {
    "duration": 83579,
    "start_time": "2025-09-11T01:21:10.341Z"
   },
   {
    "duration": 592,
    "start_time": "2025-09-11T01:22:33.930Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:22:34.531Z"
   },
   {
    "duration": 34158,
    "start_time": "2025-09-11T01:24:05.566Z"
   },
   {
    "duration": 1509,
    "start_time": "2025-09-11T01:24:39.727Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:24:41.238Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:24:41.239Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:24:41.240Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:24:41.241Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:24:41.243Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:24:41.244Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:24:41.245Z"
   },
   {
    "duration": 826987,
    "start_time": "2025-09-11T01:30:40.499Z"
   },
   {
    "duration": 8543,
    "start_time": "2025-09-11T01:44:27.489Z"
   },
   {
    "duration": 952,
    "start_time": "2025-09-11T01:44:36.033Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-11T01:44:36.988Z"
   },
   {
    "duration": 386,
    "start_time": "2025-09-11T01:44:36.992Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:44:37.380Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:44:37.382Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:44:37.383Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T01:44:37.385Z"
   },
   {
    "duration": 65481,
    "start_time": "2025-09-11T03:21:19.752Z"
   },
   {
    "duration": 6240,
    "start_time": "2025-09-11T03:22:25.235Z"
   },
   {
    "duration": 403,
    "start_time": "2025-09-11T03:22:31.477Z"
   },
   {
    "duration": 6,
    "start_time": "2025-09-11T03:22:48.319Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T03:22:50.132Z"
   },
   {
    "duration": 942,
    "start_time": "2025-09-11T03:23:05.217Z"
   },
   {
    "duration": 41690,
    "start_time": "2025-09-11T03:23:36.855Z"
   },
   {
    "duration": 5964,
    "start_time": "2025-09-11T03:24:18.548Z"
   },
   {
    "duration": 5,
    "start_time": "2025-09-11T03:24:24.514Z"
   },
   {
    "duration": 4100,
    "start_time": "2025-09-11T03:24:24.521Z"
   },
   {
    "duration": 1501,
    "start_time": "2025-09-11T03:24:28.622Z"
   },
   {
    "duration": 729660,
    "start_time": "2025-09-11T03:24:30.125Z"
   },
   {
    "duration": 51,
    "start_time": "2025-09-11T03:36:39.788Z"
   },
   {
    "duration": 561483,
    "start_time": "2025-09-11T03:36:39.841Z"
   },
   {
    "duration": 103,
    "start_time": "2025-09-11T03:46:01.333Z"
   },
   {
    "duration": 708,
    "start_time": "2025-09-11T03:46:01.440Z"
   },
   {
    "duration": 36481,
    "start_time": "2025-09-11T04:50:20.623Z"
   },
   {
    "duration": 6607,
    "start_time": "2025-09-11T04:50:57.106Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T04:51:03.715Z"
   },
   {
    "duration": 940,
    "start_time": "2025-09-11T04:51:03.721Z"
   },
   {
    "duration": 2,
    "start_time": "2025-09-11T04:51:04.664Z"
   },
   {
    "duration": 37656,
    "start_time": "2025-09-11T04:58:00.528Z"
   },
   {
    "duration": 5856,
    "start_time": "2025-09-11T04:58:38.187Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T04:58:44.044Z"
   },
   {
    "duration": 923,
    "start_time": "2025-09-11T04:58:44.050Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T04:58:44.975Z"
   },
   {
    "duration": 319278,
    "start_time": "2025-09-11T04:58:44.979Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T05:04:04.259Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T05:04:04.260Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T05:04:04.261Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T05:04:04.262Z"
   },
   {
    "duration": 63806,
    "start_time": "2025-09-11T10:05:15.946Z"
   },
   {
    "duration": 8310,
    "start_time": "2025-09-11T10:06:19.755Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T10:06:28.067Z"
   },
   {
    "duration": 2438,
    "start_time": "2025-09-11T10:06:28.073Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T10:06:30.513Z"
   },
   {
    "duration": 415423,
    "start_time": "2025-09-11T10:06:30.517Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T10:13:25.942Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T10:13:25.943Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T10:13:25.944Z"
   },
   {
    "duration": 0,
    "start_time": "2025-09-11T10:13:25.945Z"
   },
   {
    "duration": 380823,
    "start_time": "2025-09-11T10:16:11.521Z"
   },
   {
    "duration": 36125,
    "start_time": "2025-09-11T10:22:46.775Z"
   },
   {
    "duration": 6320,
    "start_time": "2025-09-11T10:23:22.902Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T10:23:29.224Z"
   },
   {
    "duration": 916,
    "start_time": "2025-09-11T10:23:29.230Z"
   },
   {
    "duration": 3,
    "start_time": "2025-09-11T10:23:30.147Z"
   },
   {
    "duration": 494719,
    "start_time": "2025-09-11T10:23:30.152Z"
   },
   {
    "duration": 4,
    "start_time": "2025-09-11T10:31:44.873Z"
   },
   {
    "duration": 255487,
    "start_time": "2025-09-11T10:31:44.879Z"
   },
   {
    "duration": 77,
    "start_time": "2025-09-11T10:36:00.368Z"
   },
   {
    "duration": 650,
    "start_time": "2025-09-11T10:36:00.450Z"
   },
   {
    "duration": 11358,
    "start_time": "2025-09-11T10:41:02.092Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
